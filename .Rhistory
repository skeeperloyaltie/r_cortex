}
# Address differences between sessions if necessary
# ...
# (Add code to handle any variations or differences between sessions)
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(caret)
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$Trial, 100, replace = FALSE, prob = NULL)
str(session[[1]]$trial)
str(session[[1]]$Trial)
str(session[[1]])
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Make predictions on Test Set 1
test_set_1_predictions <- predict(model, newdata = test_set_1)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Extract the predictor variables from the test set
test_set_1_pred <- test_set_1[, c("contrast_left", "contrast_right")]
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Extract the predictor variables from the test set
test_set_1_pred <- data.frame(
contrast_left = test_set_1$contrast_left,
contrast_right = test_set_1$contrast_right
)
# Perform the prediction using the trained model
predictions <- predict(model, newdata = test_set_1_pred)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
cat("\n")
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
cat("\n")
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
knitr::opts_chunk$set(echo = TRUE)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
# Extract relevant variables
feedback_type_1 <- test_data_1$feedback_type
contrast_left_1 <- test_data_1$contrast_left
contrast_right_1 <- test_data_1$contrast_right
spks_1 <- test_data_1$spks
feedback_type_2 <- test_data_2$feedback_type
contrast_left_2 <- test_data_2$contrast_left
contrast_right_2 <- test_data_2$contrast_right
spks_2 <- test_data_2$spks
# Create test data frames
test_df_1 <- data.frame(
feedback_type = feedback_type_1,
contrast_left = contrast_left_1,
contrast_right = contrast_right_1,
spks = spks_1
)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
# Extract relevant variables
feedback_type_1 <- test_data_1$feedback_type
contrast_left_1 <- test_data_1$contrast_left
contrast_right_1 <- test_data_1$contrast_right
spks_1 <- test_data_1$spks
feedback_type_2 <- test_data_2$feedback_type
contrast_left_2 <- test_data_2$contrast_left
contrast_right_2 <- test_data_2$contrast_right
spks_2 <- test_data_2$spks
# Check the dimensions of the variables
dim(feedback_type_1)  # Should be (100,)
dim(contrast_left_1)  # Should be (100,)
dim(contrast_right_1)  # Should be (100,)
dim(spks_1)  # Should be (100, num_neurons)
# Repeat the variables to match the number of rows in spks_1
feedback_type_1 <- rep(feedback_type_1, each = nrow(spks_1))
contrast_left_1 <- rep(contrast_left_1, each = nrow(spks_1))
contrast_right_1 <- rep(contrast_right_1, each = nrow(spks_1))
# Create the test data frame
test_df_1 <- data.frame(
feedback_type = feedback_type_1,
contrast_left = contrast_left_1,
contrast_right = contrast_right_1,
spks = as.vector(spks_1)
)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
# Extract relevant variables
feedback_type_1 <- test_data_1$feedback_type
contrast_left_1 <- test_data_1$contrast_left
contrast_right_1 <- test_data_1$contrast_right
spks_1 <- test_data_1$spks
feedback_type_2 <- test_data_2$feedback_type
contrast_left_2 <- test_data_2$contrast_left
contrast_right_2 <- test_data_2$contrast_right
spks_2 <- test_data_2$spks
# Check the dimensions of the variables
dim(feedback_type_1)  # Should be (100,)
dim(contrast_left_1)  # Should be (100,)
dim(contrast_right_1)  # Should be (100,)
dim(spks_1)  # Should be (100, num_neurons)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
# Extract relevant variables
feedback_type_1 <- test_data_1$feedback_type
contrast_left_1 <- test_data_1$contrast_left
contrast_right_1 <- test_data_1$contrast_right
spks_1 <- test_data_1$spks
# Repeat the variables to match the number of rows in spks_1
feedback_type_1 <- rep(feedback_type_1, times = 100)
contrast_left_1 <- rep(contrast_left_1, times = 100)
contrast_right_1 <- rep(contrast_right_1, times = 100)
# Check the dimensions of the variables
dim(feedback_type_1)  # Should be (100,)
dim(contrast_left_1)  # Should be (100,)
dim(contrast_right_1)  # Should be (100,)
dim(spks_1)  # Should be (100, num_neurons)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
test_data_1
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
head(test_data_1)
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
head(test_data_1[[1]])
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
head(test_data_1[1])
test_data_1 <- readRDS("test/test1.rds")
test_data_2 <- readRDS("test/test2.rds")
# Check the dimensions of spks_1
dim(spks_1)
# Reshape spks_1 to match the number of trials (100) and neurons
spks_1 <- matrix(as.vector(spks_1), nrow = 100, ncol = num_neurons)
View(test_data_1)
View(test_data_1)
View(test_set_1)
View(test_set_1)
View(test_data_1)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
test_data
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
head(test_data)
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
head(test_data)
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
# Load the necessary libraries and functions
library(gbm)  # Assuming we used the gbm package for modeling
library(readr)  # Assuming we use readRDS() function to load the test data
# Load the test data from Session 1 and Session 18
test_data_1 <- readRDS("test/test1.rds")
test_data_18 <- readRDS("test/test2.rds")
# Combine the test data from Session 1 and Session 18
test_data <- rbind(test_data_1, test_data_18)
# Preprocess the test data (if necessary) - perform any necessary transformations or feature engineering
# Extract the input features from the test data
test_features <- test_data[, c("contrast_left", "contrast_right")]
# Make predictions using the trained model
test_predictions <- predict(trained_model, newdata = test_features, type = "response")  # Adjust "trained_model" with the name of your trained model
