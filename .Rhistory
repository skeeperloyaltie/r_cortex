# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(!is.finite(spike_trains))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
num_neurons <- sapply(session, function(s) sum(sapply(s$trial, function(t) nrow(t$spks))))
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
num_neurons <- sapply(session, function(s) sum(sapply(s$trial, function(t) nrow(t$spks))))
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
num_neurons <- sapply(session, function(s) sum(sapply(s$trial, function(t) length(t$spks))))
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
num_neurons <- sapply(session, function(s) sum(sapply(s$trial, function(t) nrow(t$spks))))
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
# Number of trials across sessions and mice
num_trials <- sapply(session, function(s) length(s$trial))
# Stimuli conditions across sessions and mice
stimuli_conditions <- sapply(session, function(s) unique(paste(sapply(s$trial, function(t) paste(t$contrast_left, t$contrast_right, sep = " ")), collapse = ", ")))
# Feedback types across sessions and mice
feedback_types <- sapply(session, function(s) unique(sapply(s$trial, function(t) t$feedback_type)))
# Print the summary of data structures across sessions
for (i in 1:length(session)) {
cat("Session", i, "\n")
cat("Number of neurons:", num_neurons[i], "\n")
cat("Number of trials:", num_trials[i], "\n")
cat("Stimuli conditions:", stimuli_conditions[i], "\n")
cat("Feedback types:", feedback_types[i], "\n\n")
}
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
# Number of trials across sessions and mice
num_trials <- sapply(session, function(s) length(s$trial))
# Stimuli conditions across sessions and mice
stimuli_conditions <- sapply(session, function(s) unique(paste(sapply(s$trial, function(t) paste(t$contrast_left, t$contrast_right, sep = " ")), collapse = ", ")))
# Feedback types across sessions and mice
feedback_types <- sapply(session, function(s) unique(sapply(s$trial, function(t) t$feedback_type)))
# (i) Describe the data structures across sessions
# Number of sessions
num_sessions <- length(session)
# Number of neurons, trials, stimuli conditions, and feedback types for each session
session_summary <- data.frame(
Session = 1:num_sessions,
Num_Neurons = sapply(session, function(s) length(s$spks)),
Num_Trials = sapply(session, function(s) length(s$trial)),
Stimuli_Conditions = sapply(session, function(s) unique(paste(s$trial$contrast_left, s$trial$contrast_right, sep = " "))),
Feedback_Types = sapply(session, function(s) unique(s$trial$feedback_type))
)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
cat("Trial", i, "\n")
cat("Feedback type:", feedback_type[i], "\n")
cat("Left contrast:", contrast_left[i], "\n")
cat("Right contrast:", contrast_right[i], "\n")
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
cat("\n")
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Explore changes across trials
# Select a specific session and trial for analysis
session_num <- 1
trial_num <- 1
# Extract the relevant data for the selected session and trial
selected_session <- session[[session_num]]
selected_trial <- selected_session$trial[[trial_num]]
# Extract the spike trains for the selected trial
spike_trains <- selected_trial$spks
# Check for missing or invalid data in spike trains
if (is.null(spike_trains) || any(sapply(spike_trains, is.null)) || any(sapply(spike_trains, function(x) any(!is.finite(x))))) {
cat("Invalid or missing data in spike trains.")
} else {
# Visualize the spike trains
plot(selected_trial$time, spike_trains[1, ], type = "l", xlab = "Time", ylab = "Number of Spikes", main = "Spike Trains")
}
# Explore homogeneity and heterogeneity across sessions and mice
# Number of neurons across sessions and mice
# Number of trials across sessions and mice
num_trials <- sapply(session, function(s) length(s$trial))
# Stimuli conditions across sessions and mice
stimuli_conditions <- sapply(session, function(s) unique(paste(sapply(s$trial, function(t) paste(t$contrast_left, t$contrast_right, sep = " ")), collapse = ", ")))
# Feedback types across sessions and mice
feedback_types <- sapply(session, function(s) unique(sapply(s$trial, function(t) t$feedback_type)))
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Address differences between sessions if necessary
# ...
# (Add code to handle any variations or differences between sessions)
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(caret)
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$trial, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$Trial, 100, replace = FALSE, prob = NULL)
str(session[[1]]$trial)
str(session[[1]]$Trial)
str(session[[1]])
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$trial, 100, replace = FALSE)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Make predictions on Test Set 1
test_set_1_predictions <- predict(model, newdata = test_set_1)
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Extract the predictor variables from the test set
test_set_1_pred <- test_set_1[, c("contrast_left", "contrast_right")]
# Randomly select 100 trials from Session 1 as Test Set 1
test_set_1 <- sample(session[[1]]$spks, 100, replace = FALSE, prob = NULL)
# Randomly select 100 trials from Session 18 as Test Set 2
test_set_2 <- sample(session[[18]]$spks, 100, replace = FALSE)
# Extract the predictor variables from the test set
test_set_1_pred <- data.frame(
contrast_left = test_set_1$contrast_left,
contrast_right = test_set_1$contrast_right
)
# Perform the prediction using the trained model
predictions <- predict(model, newdata = test_set_1_pred)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
cat("\n")
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
cat("\n")
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(readr)
# Define a function to perform exploratory data analysis for each session
perform_eda <- function(session_data) {
# Extract relevant variables
feedback_type <- session_data$feedback_type
contrast_left <- session_data$contrast_left
contrast_right <- session_data$contrast_right
spks <- session_data$spks
# Describe data structures
num_neurons <- nrow(spks)
num_trials <- length(feedback_type)
stimuli_conditions <- unique(paste(contrast_left, contrast_right))
feedback_types <- unique(feedback_type)
cat("Number of neurons:", num_neurons, "\n")
cat("Number of trials:", num_trials, "\n")
cat("Stimuli conditions:", stimuli_conditions, "\n")
cat("Feedback types:", feedback_types, "\n")
# Explore neural activities during each trial
for (i in 1:num_trials) {
# Further analyze the spike train data for each trial
spike_train <- spks[[i]]
# Perform desired analysis on spike_train
}
# Explore changes across trials
# Explore homogeneity and heterogeneity across sessions and mice
}
# Load the RDS files and perform exploratory data analysis for each session
session <- list()
for (i in 1:18) {
session[[i]] <- readRDS(paste('data/session', i, '.rds', sep=''))
cat("Session", i, "\n")
perform_eda(session[[i]])
}
# Create an empty data frame to store the integrated data
integrated_data <- data.frame()
# Combine data across sessions
for (i in 1:length(session)) {
# Extract relevant variables
feedback_type <- session[[i]]$feedback_type
contrast_left <- session[[i]]$contrast_left
contrast_right <- session[[i]]$contrast_right
spks <- session[[i]]$spks
# Create a data frame for the session
session_data <- data.frame(
feedback_type = feedback_type,
contrast_left = contrast_left,
contrast_right = contrast_right,
session = i
)
# Append the session data to the integrated data frame
integrated_data <- rbind(integrated_data, session_data)
}
# Print the integrated data frame
tail(integrated_data)
library(tidyverse)
library(caret)
# Load required libraries
library(dplyr)
# Preparing the data for model training and prediction
# Select the relevant variables from the integrated data
selected_data <- integrated_data %>%
select(feedback_type, contrast_left, contrast_right, session)
# Convert feedback_type to a factor with two levels
selected_data$feedback_type <- factor(selected_data$feedback_type, levels = c(-1, 1), labels = c("failure", "success"))
# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- sample(nrow(selected_data), nrow(selected_data) * 0.8) # 80% for training
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]
# Build the prediction model
model <- train(
feedback_type ~ contrast_left + contrast_right + session,
data = train_data,
method = "gbm",  # Replace with the desired model method (e.g., "randomForest", "glm", etc.)
trControl = trainControl(method = "cv", number = 5), # Cross-validation with 5 folds
verbose = FALSE
)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the performance of the model
accuracy <- confusionMatrix(predictions, test_data$feedback_type)$overall["Accuracy"]
cat("Model Accuracy:", accuracy, "\n")
